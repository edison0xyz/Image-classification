{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training images using scikit-learn \n",
    "\n",
    "Self-training image with scikit-learn\n",
    "\n",
    "Reference: \n",
    "* http://scikit-image.org/docs/dev/auto_examples/plot_hog.html\n",
    "* http://www.vlfeat.org/overview/hog.html\n",
    "* http://nbviewer.jupyter.org/github/BVLC/caffe/blob/master/examples/00-classification.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.feature import hog\n",
    "from skimage.transform import resize\n",
    "from skimage import io, data, color, exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA = '/Users/edison/Desktop/Yelp/project/'\n",
    "PHOTOS_PATH = DATA + 'train_photos/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Codes to demonstrate features of HOG. This portion do not affect the results of the image classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = io.imread(PHOTOS_PATH + '10.jpg')\n",
    "image = color.rgb2gray(image)\n",
    "fd, hog_image = hog(image, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(1, 1), visualise=True)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4), sharex=True, sharey=True)\n",
    "\n",
    "\n",
    "#input image \n",
    "ax1.axis('off')\n",
    "ax1.imshow(image, cmap=plt.cm.gray)\n",
    "ax1.set_title('Input image')\n",
    "ax1.set_adjustable('box-forced')\n",
    "hog_image = exposure.rescale_intensity(hog_image, in_range=(0, 0.02))\n",
    "\n",
    "\n",
    "#output image \n",
    "ax2.axis('off')\n",
    "ax2.imshow(hog_image, cmap=plt.cm.gray)\n",
    "ax2.set_title('Histogram of Oriented Gradients')\n",
    "ax1.set_adjustable('box-forced')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When given a image path on the system directory, function converts image to grayscale, resize it to 256 x 256, and returns a HOG object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(image_path): \n",
    "    image = io.imread(image_path)\n",
    "    image = color.rgb2gray(image)\n",
    "    image = resize(image, (256, 256)) #resize to run faster \n",
    "    return hog(image, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(1, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Initialise h5py files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = h5py.File(DATA+'train_image_HOGfeatures.h5','w')\n",
    "filenames = f.create_dataset('photo_id',(0,), maxshape=(None,),dtype='|S54')\n",
    "feature = f.create_dataset('feature',(0,2048), maxshape = (None,2048))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>photo_id</th>\n",
       "      <th>business_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>204149</td>\n",
       "      <td>3034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52779</td>\n",
       "      <td>2805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>278973</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195284</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19992</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   photo_id  business_id\n",
       "0    204149         3034\n",
       "1     52779         2805\n",
       "2    278973          485\n",
       "3    195284          485\n",
       "4     19992          485"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_photos_csv = pd.read_csv(DATA+'train_photo_to_biz_ids.csv')\n",
    "train_photos_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_images = [os.path.join(PHOTOS_PATH, str(x)+'.jpg') for x in train_photos_csv['photo_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/edison/Desktop/Yelp/project/train_photos/52779.jpg',\n",
       " '/Users/edison/Desktop/Yelp/project/train_photos/278973.jpg',\n",
       " '/Users/edison/Desktop/Yelp/project/train_photos/195284.jpg',\n",
       " '/Users/edison/Desktop/Yelp/project/train_photos/19992.jpg']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/edison/Desktop/Yelp/project/train_photos/52779.jpg'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images:  234842\n",
      "Images Processed  10000\n",
      "Images Processed  20000\n",
      "Images Processed  30000\n",
      "Images Processed  40000\n",
      "Images Processed  50000\n",
      "Images Processed  60000\n",
      "Images Processed  70000\n",
      "Images Processed  80000\n",
      "Images Processed  90000\n",
      "Images Processed  100000\n",
      "Images Processed  110000\n",
      "Images Processed  120000\n",
      "Images Processed  130000\n",
      "Images Processed  140000\n",
      "Images Processed  150000\n",
      "Images Processed  160000\n",
      "Images Processed  170000\n",
      "Images Processed  180000\n",
      "Images Processed  190000\n",
      "Images Processed  200000\n",
      "Images Processed  210000\n",
      "Images Processed  220000\n",
      "Images Processed  230000\n",
      "Images Processed  234842\n",
      "\n",
      "Time taken for feature extraction (HOG): 7207.196549s\n"
     ]
    }
   ],
   "source": [
    "# Training Images \n",
    "print \"Number of training images: \", len(train_images)\n",
    "start = time.time()\n",
    "counter = 0\n",
    "for i in range(0, len(train_images)): \n",
    "    feature = extract_features(train_images[i])\n",
    "    counter = counter + 1 \n",
    "    f = h5py.File(DATA + 'train_image_HOGfeatures.h5', 'r+')\n",
    "    f['photo_id'].resize((counter,))\n",
    "    f['photo_id'][i] = train_images[i]\n",
    "    f['feature'].resize((counter,feature.shape[0]))\n",
    "    f['feature'][i, :] = feature\n",
    "    f.close()\n",
    "    if counter%10000==0 or counter==len(train_images): \n",
    "        print \"Images Processed \", counter\n",
    "\n",
    "\n",
    "end = time.time() \n",
    "print '\\nTime taken for feature extraction (HOG): %fs' % (end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract feature function \n",
    "* photo_to_biz: photo ID to business ID (csv file) \n",
    "* directory (e.g. train_photos/) \n",
    "* output filename for the h5 file\n",
    "\n",
    "Generic function to extract features and write into an output features h5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_feature_function(photo_to_biz, directory, output_file): \n",
    "    \n",
    "    # Output h5py file \n",
    "    f = h5py.File(DATA+ output_file,'w')\n",
    "    filenames = f.create_dataset('photo_id',(0,), maxshape=(None,),dtype='|S54')\n",
    "    feature = f.create_dataset('feature',(0,2048), maxshape = (None,2048))\n",
    "    f.close()\n",
    "    \n",
    "    photos = pd.read_csv(DATA + photo_to_biz)\n",
    "    folder = DATA + directory \n",
    "    images = [os.path.join(folder, str(x)+'.jpg') for x in photos['photo_id']]\n",
    "    \n",
    "    total_count = len(images)\n",
    "    \n",
    "    print \"Number of training images: \", total_count\n",
    "    start = time.time()\n",
    "    counter = 0\n",
    "    for i in range(0, total_count): \n",
    "        feature = extract_features(images[i])\n",
    "        counter = counter + 1 \n",
    "        f = h5py.File(DATA + output_file, 'r+')\n",
    "        f['photo_id'].resize((counter,))\n",
    "        f['photo_id'][i] = images[i]\n",
    "        f['feature'].resize((counter,feature.shape[0]))\n",
    "        f['feature'][i, :] = feature\n",
    "        f.close()\n",
    "        if counter%20000==0 or counter==len(images): \n",
    "            print \"Images Processed \", counter\n",
    "\n",
    "\n",
    "    end = time.time() \n",
    "    print '\\nTime taken for feature extraction (HOG): %fs' % (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images:  1190225\n",
      "Images Processed  20000\n",
      "Images Processed  40000\n",
      "Images Processed  60000\n",
      "Images Processed  80000\n",
      "Images Processed  100000\n",
      "Images Processed  120000\n",
      "Images Processed  140000\n",
      "Images Processed  160000\n",
      "Images Processed  180000\n",
      "Images Processed  200000\n",
      "Images Processed  220000\n",
      "Images Processed  240000\n",
      "Images Processed  260000\n",
      "Images Processed  280000\n",
      "Images Processed  300000\n",
      "Images Processed  320000\n",
      "Images Processed  340000\n",
      "Images Processed  360000\n",
      "Images Processed  380000\n",
      "Images Processed  400000\n",
      "Images Processed  420000\n",
      "Images Processed  440000\n",
      "Images Processed  460000\n",
      "Images Processed  480000\n",
      "Images Processed  500000\n",
      "Images Processed  520000\n",
      "Images Processed  540000\n",
      "Images Processed  560000\n",
      "Images Processed  580000\n",
      "Images Processed  600000\n",
      "Images Processed  620000\n",
      "Images Processed  640000\n",
      "Images Processed  660000\n",
      "Images Processed  680000\n",
      "Images Processed  700000\n",
      "Images Processed  720000\n",
      "Images Processed  740000\n",
      "Images Processed  760000\n",
      "Images Processed  780000\n",
      "Images Processed  800000\n",
      "Images Processed  820000\n",
      "Images Processed  840000\n",
      "Images Processed  860000\n",
      "Images Processed  880000\n",
      "Images Processed  900000\n",
      "Images Processed  920000\n",
      "Images Processed  940000\n",
      "Images Processed  960000\n",
      "Images Processed  980000\n",
      "Images Processed  1000000\n",
      "Images Processed  1020000\n",
      "Images Processed  1040000\n",
      "Images Processed  1060000\n",
      "Images Processed  1080000\n",
      "Images Processed  1100000\n",
      "Images Processed  1120000\n",
      "Images Processed  1140000\n",
      "Images Processed  1160000\n",
      "Images Processed  1180000\n",
      "Images Processed  1190225\n",
      "\n",
      "Time taken for feature extraction (HOG): 53511.833460s\n"
     ]
    }
   ],
   "source": [
    "#test data \n",
    "extract_feature_function('test_photo_to_biz.csv', 'test_photos/', 'test_image_HOGfeatures.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
